{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "en = imp.load_source('encode', '/home/arturas/Projects/ProteoDNN/Utils/encode.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oxy = pd.read_csv('data/OxidationAll.txt', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Peptide                        object\n",
       "Proteins                       object\n",
       "Identification Score          float64\n",
       "Pair Score                    float64\n",
       "[L]ID                           int64\n",
       "[L]Modifications              float64\n",
       "[L]Mass                       float64\n",
       "[L]Charge                       int64\n",
       "[L]m/z                        float64\n",
       "[L]Retention Time (min)       float64\n",
       "[H]ID                           int64\n",
       "[H]Modifications               object\n",
       "[H]Mass                       float64\n",
       "[H]Charge                       int64\n",
       "[H]m/z                        float64\n",
       "[H]Retention Time (min)       float64\n",
       "Mass Difference (Observed)    float64\n",
       "Mass Difference (Expected)    float64\n",
       "Mass Difference (Delta)       float64\n",
       "Retention (Delta)             float64\n",
       "Unnamed: 20                   float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oxy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oxy_ = oxy[(oxy['[L]Retention Time (min)'] > 20) & (oxy['[L]Retention Time (min)'] < 80)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "peptides = [np.array(en.encode_aa_counts(pep)).reshape(-1,1) for pep in oxy_.iloc[:,0]]\n",
    "peptides = np.concatenate(peptides,axis=1)\n",
    "peptides = peptides.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ret_delta = oxy_.iloc[:,19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178884, 20)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalize features\n",
    "peptides_norm = (peptides - np.mean(peptides, axis=0))/np.std(peptides,axis=0)\n",
    "peptides_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append_bias_reshape(features,labels):\n",
    "    n_training_samples = features.shape[0]\n",
    "    n_dim = features.shape[1]\n",
    "    f = np.reshape(np.c_[np.ones(n_training_samples),features],[n_training_samples,n_dim + 1])\n",
    "    l = np.reshape(labels,[n_training_samples,1])\n",
    "    return f, l\n",
    "\n",
    "#Xdat, Ydat = append_bias_reshape(peptides_norm, ret_delta)\n",
    "Xdat = peptides#_norm\n",
    "Ydat = ret_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arturas/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/__main__.py:6: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/home/arturas/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/__main__.py:8: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    }
   ],
   "source": [
    "n_dim = Xdat.shape[1]\n",
    "\n",
    "rnd_indices = np.random.rand(len(Xdat)) < 0.80\n",
    "\n",
    "trX = Xdat[rnd_indices]\n",
    "trY = Ydat[rnd_indices].reshape(-1,1)\n",
    "teX = Xdat[~rnd_indices]\n",
    "teY = Ydat[~rnd_indices].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.39 ],\n",
       "       [  7.79 ],\n",
       "       [ 13.45 ],\n",
       "       [  9.315]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trY[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Weight init and model declaration\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))\n",
    "\n",
    "def model(X, w_h, w_h2, w_o ):\n",
    "    h = tf.nn.relu(tf.matmul(X, w_h))\n",
    "    h2 = tf.nn.relu(tf.matmul(h, w_h2))\n",
    "    #h3 = tf.nn.relu(tf.matmul(h2, w_h3))\n",
    "    #h4 = tf.nn.relu(tf.matmul(h3, w_h4))\n",
    "    return tf.matmul(h2, w_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Accuracy measure\n",
    "def accMeas(mat, trueMat):\n",
    "    mat[mat>0.5] = 1.0\n",
    "    mat[mat<=0.5] = 0.0\n",
    "    correct = np.zeros(mat.shape)\n",
    "    correct[mat==trueMat] = 1\n",
    "    miscrate =  correct.mean(axis=0)\n",
    "    return(miscrate)\n",
    "\n",
    "def MSE(pred, trueDat):\n",
    "    return np.sum((pred-trueDat)**2) / len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating symbolic variables and initializing weights\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 20])\n",
    "Y = tf.placeholder(\"float\", [None, 1])\n",
    "\n",
    "w_h = init_weights([20, 100])\n",
    "w_h2 = init_weights([100,50])\n",
    "#w_h3 = init_weights([350,150])\n",
    "w_o = init_weights([50, 1])\n",
    "\n",
    "py_x = model(X, w_h, w_h2, w_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cost function and optimizer\n",
    "#cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(py_x, Y))\n",
    "cost = tf.reduce_mean(tf.square(py_x-Y))\n",
    "#train_op = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)\n",
    "train_op = tf.train.GradientDescentOptimizer(0.03).minimize(cost)\n",
    "#predict_op = tf.nn.sigmoid(py_x)\n",
    "predict_op = py_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 8.56751451]\n",
      "100 [ 8.56751305]\n",
      "200 [ 8.56751305]\n",
      "300 [ 8.56751305]\n",
      "400 [ 8.56751305]\n",
      "500 [ 8.56751305]\n",
      "600 [ 8.56751305]\n",
      "700 [ 8.56751306]\n",
      "800 [ 8.56751306]\n",
      "900 [ 8.56751306]\n",
      "999 [ 8.56751306]\n",
      "Training Error - correct: = 90.69949208782508\n",
      "Test Error - correct:  = 89.0102760767894\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    # you need to initialize all variables\n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "    for i in range(1000):\n",
    "        for start, end in zip(range(0, len(trX), 200), range(200, len(trX), 200)):\n",
    "            sess.run(train_op, feed_dict={X: trX[start:end], Y: trY[start:end]})\n",
    "        if(i%100==0):\n",
    "            print(i, (np.abs(sess.run(predict_op, feed_dict={X: teX, Y: teY[:]}) - teY[:])).mean(axis=0))\n",
    "    print(i, (np.abs(sess.run(predict_op, feed_dict={X: teX, Y: teY[:]}) - teY[:])).mean(axis=0))\n",
    "    \n",
    "    print(\"Training Error - correct: = {}\".format(MSE(sess.run(predict_op, feed_dict={X: trX, Y: trY}),trY)))\n",
    "    print(\"Test Error - correct:  = {}\".format(MSE(sess.run(predict_op, feed_dict={X: teX, Y: teY}),teY)))\n",
    "    #print(\"New data:\")\n",
    "    #print(np.round(sess.run(predict_op, feed_dict={X: testExt[1:5],Y:teY[1:5]})))\n",
    "    #np.savetxt(\"/home/arturas/Desktop/pred.txt\",sess.run(predict_op, feed_dict={X: trX, Y: trY}), delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
